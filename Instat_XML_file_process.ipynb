{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Instat XML file process.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "zbQTu9ANb3rG",
        "4YZjFbfMjgGD",
        "IicC6fu_chAF",
        "WpQZm5Pod90g",
        "zhv64lRaeacD",
        "PLBYNhWKetBC",
        "bvE-GJELhV3N",
        "xr5yvcZqiFCq",
        "60RIrfroi25a",
        "8Q1T9xP3jL_w",
        "Z7TSctbdjr_K",
        "h1IrljbUj_po",
        "vkc6rVm3kRhT",
        "4pVaFM3gkoTp",
        "IeZaI5S3lBRH",
        "LzxuzKVNmIPR",
        "yxCLZXFInTzI",
        "kc0EU0l1yogk",
        "WanfPQBVz2NI",
        "B22Ds0gT0Lal"
      ],
      "mount_file_id": "18-Oy-e5Qjk9D2ZPghmU5fAJPiUlJqDs5",
      "authorship_tag": "ABX9TyOhsHuDsufdW8QT9DMShcDT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adlihs/instatXML/blob/main/Instat_XML_file_process.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Process to work with Instat's xml file"
      ],
      "metadata": {
        "id": "w_DXsUfibvdr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import libraries"
      ],
      "metadata": {
        "id": "zbQTu9ANb3rG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOngInXqbsYW"
      },
      "outputs": [],
      "source": [
        "!pip install pandas_read_xml\n",
        "!pip install -U pandasql\n",
        "import pandas_read_xml as pdx \n",
        "from pandas_read_xml import flatten, fully_flatten, auto_separate_tables\n",
        "import os,glob \n",
        "import pandas as pd\n",
        "import time\n",
        "import numpy as np\n",
        "from pandasql import sqldf "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup the name of the tournament"
      ],
      "metadata": {
        "id": "4YZjFbfMjgGD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nombre_torneo = \"Clausura 2022\""
      ],
      "metadata": {
        "id": "fg2M0eKVjlns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup the google drive folder's path\n",
        "The idea is to download all the xml from Instat and put all in a google drive folder."
      ],
      "metadata": {
        "id": "IicC6fu_chAF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content/drive/My Drive/XML Clausura 2022\" #this is an example of my folder's path"
      ],
      "metadata": {
        "id": "2VhocWDtcrx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remove excel files from previous process\n",
        "The script will generate an excel file for each xml, so the idea is to remove the files from previous process."
      ],
      "metadata": {
        "id": "WpQZm5Pod90g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Finding and removing old excel files...')\n",
        "excel_files = []\n",
        "for file in glob.glob(\"*.xlsx\"):\n",
        "    excel_files.append(file)\n",
        "\n",
        "for file in excel_files:\n",
        "  os.remove(file)\n",
        "\n",
        "print('done!')"
      ],
      "metadata": {
        "id": "QofEjx2eeQrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's find all the XML files in the folder"
      ],
      "metadata": {
        "id": "zhv64lRaeacD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Finding xml files...')\n",
        "xml_files = []\n",
        "for file in glob.glob(\"*.xml\"):\n",
        "    xml_files.append(file)\n",
        "\n",
        "print('done!')"
      ],
      "metadata": {
        "id": "BWynRsJYeebn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate an excel file for each xml file"
      ],
      "metadata": {
        "id": "PLBYNhWKetBC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Creating excel files from xmls')\n",
        "open_file =\"\"\n",
        "for xml in xml_files:\n",
        "  # This line will remove the name of the competion from the xml file name\n",
        "  file_name = xml.replace('--Costa-Rica--Primera-Division','')\n",
        "  # This line will remove the text '.xml' from the variable 'file_name' \n",
        "  file_name = file_name.replace('.xml','')\n",
        "  # This line will create a dataframe with the xml data\n",
        "  open_file = pdx.read_xml(xml, ['file', 'ALL_INSTANCES', 'instance'], root_is_rows=False)\n",
        "  # This line is to create a new column named 'file_name', the column will contain the information of the game\n",
        "  open_file[\"file_name\"] = file_name\n",
        "  # This line will generate an excel file\n",
        "  open_file.to_excel(file_name + \".xlsx\")\n",
        "  #print(open_file.file_name)\n",
        "\n",
        "print('done!')\n",
        "open_file"
      ],
      "metadata": {
        "id": "9iphC2-cewft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Merge all excel files in one dataframe"
      ],
      "metadata": {
        "id": "bvE-GJELhV3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Merging files...')\n",
        "all_data = pd.DataFrame()\n",
        "for f in glob.glob(\"*.xlsx\"):\n",
        "    df = pd.read_excel(f)\n",
        "    all_data = all_data.append(df,ignore_index=True)\n",
        "print('done!')\n",
        "all_data"
      ],
      "metadata": {
        "id": "-sA1wwUnhbE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split column `'Label'` by comma `','`"
      ],
      "metadata": {
        "id": "xr5yvcZqiFCq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create new dataframe with the new columns from the column 'LABEL'\n",
        "print('Creating new data frame')\n",
        "all_data2 = all_data['label'].str.split(',', expand=True)\n",
        "\n",
        "\n",
        "#Merge original dataframe and new dataframe\n",
        "print('Merging dataframes')\n",
        "all_data = pd.concat([all_data, all_data2], axis=1, sort=False)\n",
        "\n",
        "###REMOVE UNNCESSARY COLUMNS\n",
        "print('Removing columns')\n",
        "all_data.drop('label', inplace=True, axis=1)\n",
        "all_data.drop(0, inplace=True, axis=1)\n",
        "all_data.drop(2, inplace=True, axis=1)\n",
        "all_data.drop(4, inplace=True, axis=1)\n",
        "\n",
        "#### RENAME NEW COLUMNS (Teams, Actions, Time)\n",
        "print('Reanaming columns')\n",
        "all_data = all_data.rename(columns={1: \"Equipos\", 3: \"Acciones\",5:\"Tiempo\"})\n",
        "\n",
        "\n",
        "#### REPLACE CHARACTERS IN COLUMNS EQUIPOS, ACCIONES, TIEMPO\n",
        "print('Replacing special characters')\n",
        "import re\n",
        "chars_to_remove = ['.', '-', '(', ')',']','\\'', '','}',':']\n",
        "regular_expression = '[' + re.escape (''. join (chars_to_remove)) + ']'\n",
        "\n",
        "all_data['Equipos'] = all_data['Equipos'].str.replace(regular_expression, '', regex=True)\n",
        "all_data['Acciones'] = all_data['Acciones'].str.replace(regular_expression, '', regex=True)\n",
        "all_data['Tiempo'] = all_data['Tiempo'].str.replace(regular_expression, '', regex=True)\n",
        "\n",
        "all_data['Equipos'] = all_data['Equipos'].str.replace('text','')\n",
        "all_data['Acciones'] = all_data['Acciones'].str.replace('text','')\n",
        "all_data['Tiempo'] = all_data['Tiempo'].str.replace('text','')\n",
        "\n",
        "\n",
        "print('done!')\n"
      ],
      "metadata": {
        "id": "F5OFz83ciM8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preview the dataframe"
      ],
      "metadata": {
        "id": "60RIrfroi25a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_data.head(20)"
      ],
      "metadata": {
        "id": "XrAzmtd6i5BD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get new columns from `file_name` column"
      ],
      "metadata": {
        "id": "8Q1T9xP3jL_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#New column 'fecha_partido' (game_date)\n",
        "print('creating new column fecha_partido')\n",
        "all_data['fecha_partido'] = all_data['file_name'].str[:10]\n",
        "\n",
        "\n",
        "#New column 'nombre_torneo' (tournament_name)\n",
        "print('creating new column nombre_torneo')\n",
        "all_data['nombre_torneo'] = nombre_torneo\n",
        "\n",
        "#remove game date from string\n",
        "print('Removing game date from string')\n",
        "all_data['file_name'] = all_data['file_name'].str[10:]\n",
        "\n",
        "\n",
        "#Remove last 20 characters\n",
        "print('removing unnecessary last 22 last characters')\n",
        "all_data['file_name'] = all_data['file_name'].str[:-21]\n",
        "\n",
        "####RENAME COLUMN FILE_NAME\n",
        "print('Reanaming column')\n",
        "all_data = all_data.rename(columns={'file_name': \"Partido\"})\n",
        "\n",
        "print('done!')"
      ],
      "metadata": {
        "id": "TiJYyR1ZjM6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preview the dataframe with the new columns"
      ],
      "metadata": {
        "id": "Z7TSctbdjr_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_data.head(20)"
      ],
      "metadata": {
        "id": "N0kHWJvvjunw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remove white spaces from the column `Acciones` (actions)"
      ],
      "metadata": {
        "id": "h1IrljbUj_po"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TRIM spaces\n",
        "all_data['Acciones'] = all_data['Acciones'].str.strip()\n",
        "all_data['Equipos'] = all_data['Equipos'].str.strip()"
      ],
      "metadata": {
        "id": "XKUoqrZ8kKfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup columns with the `home team name` and the `away team name`"
      ],
      "metadata": {
        "id": "vkc6rVm3kRhT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace score in game description with @\n",
        "all_data[\"partido_text\"] = all_data[\"Partido\"].replace(to_replace=r'[-]+\\d[-]+\\d+[-]', value='@', regex=True)\n",
        "\n",
        "# Create a temp dataframe with columns 'home_team'/'away_team'\n",
        "localia_df = all_data['partido_text'].str.split('@', expand=True)\n",
        "\n",
        "# Merge new temp dataframe with all_data dataframe\n",
        "all_data = pd.concat([all_data, localia_df], axis=1, sort=False)\n",
        "\n",
        "#Rename new columns\n",
        "all_data.rename(columns={0: 'equipo_casa', 1: 'equipo_visita'}, inplace=True)\n",
        "\n",
        "#Drop column 'partido_text'\n",
        "all_data.drop('partido_text', inplace=True, axis=1)"
      ],
      "metadata": {
        "id": "UTK5B_LQklTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preview the dataframe with the new changes"
      ],
      "metadata": {
        "id": "4pVaFM3gkoTp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_data.head(20)"
      ],
      "metadata": {
        "id": "T-EEgf4ZksfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get columns for: **`Score`**, **`Home and Away goals`**"
      ],
      "metadata": {
        "id": "IeZaI5S3lBRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the score from column 'Partido' (game)\n",
        "all_data[\"marcador\"] = all_data['Partido'].str.findall(r'\\d[-]+\\d+')\n",
        "\n",
        "#convert column 'marcador' to string\n",
        "all_data[\"marcador\"] = all_data[\"marcador\"].astype('str') \n",
        "\n",
        "# marcador en formato string\n",
        "all_data[\"marcador\"] = all_data[\"marcador\"].str.slice(start=2, stop=-2)\n",
        "\n",
        "\n",
        "#New column with the home team goals ('goles_local')\n",
        "all_data['goles_local'] = all_data[\"marcador\"].str.slice(start=0, stop=1)\n",
        "\n",
        "#New column with the away team goals ('goles_visita')\n",
        "all_data['goles_visita'] = all_data[\"marcador\"].str.slice(start=2, stop=3)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-REad5v5lXK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preview the dataframe with the changes"
      ],
      "metadata": {
        "id": "LzxuzKVNmIPR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_data.head(20)"
      ],
      "metadata": {
        "id": "GEPjrnGMmL3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup a column with the team that \"suffers\" the action\n"
      ],
      "metadata": {
        "id": "p8U8i8Opm3fw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a list of our conditions\n",
        "\n",
        "conditions = [\n",
        "    (all_data[\"Equipos\"] == all_data[\"equipo_casa\"]),\n",
        "    (all_data[\"Equipos\"] == all_data[\"equipo_visita\"])]\n",
        "\n",
        "# create a list of the values we want to assign for each condition\n",
        "values = [all_data[\"equipo_visita\"], all_data[\"equipo_casa\"]]\n",
        "\n",
        "# create a new column and use np.select to assign values to it using our lists as arguments\n",
        "all_data[\"rival\"] = np.select(conditions, values)\n"
      ],
      "metadata": {
        "id": "nZock7yImORp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preview the changes"
      ],
      "metadata": {
        "id": "yxCLZXFInTzI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_data.head(30)"
      ],
      "metadata": {
        "id": "VXvx45ranVcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remove unnecesary columns"
      ],
      "metadata": {
        "id": "kc0EU0l1yogk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_data.drop(all_data.columns[0], axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "km3Xn-MIysgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export the consolidated dataframe to Excel file"
      ],
      "metadata": {
        "id": "WanfPQBVz2NI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print('Creating excel file with the dataframe all_data')\n",
        "all_data.to_excel('UNAFUT_'+nombre_torneo+'.xlsx') # YOU CAN SETUP THE FILE NAME THAT YOU WANT\n",
        "print('done!')"
      ],
      "metadata": {
        "id": "dmFK2GT1zmdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Delete all excel files except the file created in the previous step"
      ],
      "metadata": {
        "id": "B22Ds0gT0Lal"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Detecting all .xlsx files')\n",
        "excel_files = []\n",
        "for file in glob.glob(\"*.xlsx\"):\n",
        "    excel_files.append(file)\n",
        "\n",
        "print('Removing all excel files except UNAFUT_' + nombre_torneo +'.xlsx')\n",
        "for file in excel_files:\n",
        "  if file != ('UNAFUT_' + nombre_torneo + '.xlsx') : # HERE CHANGE AND PUT THE FILE NAME YOU PUT IN THE PREVIOUS STEP\n",
        "    os.remove(file)\n",
        "\n",
        "print('All process is done!')"
      ],
      "metadata": {
        "id": "rzczzVE2z-2l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}